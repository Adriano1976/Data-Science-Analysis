{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dfc7381-4a0f-40be-8e01-d9daf3e89c57",
   "metadata": {},
   "source": [
    "### Prof. Fernando Amaral - www.eia.ai\n",
    "### Contribuição: Adriano Santos\n",
    "#### <strong><font color=orange>Machine Learning com Spark</font></strong>\n",
    "## <strong>`OneHotEncoder`</strong>\n",
    "\n",
    "- O conceito por trás do OneHotEncoding é produzir um único atributo de saída com uma matriz densa a partir de atributos numéricos. O OneHotEncoding espera atributos numéricos e pode ser utilizado o StringIndexer para transformá-los.\n",
    "- OneHotEncoding é uma técnica de processamento de dados que produz um único atributo de saída com uma matriz densa a partir de n atributos numéricos. Por exemplo, se tivermos um atributo de entrada que pode ter três valores diferentes 'A', 'B', 'C', o OneHotEncoder criará três atributos binários correspondentes. Se o valor for 'A', o atributo 'A' será 1 e os outros 0. Da mesma forma, para 'B' e 'C'. Se tivermos dados que não são numéricos para começar, podemos usar outra técnica, como o StringIndexer, para converter esses dados em numéricos antes que possam ser utilizados pelo OneHotEncoder.\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e1d205",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`pyspark`**, uma biblioteca para processamento de dados distribuídos em Python, para criar uma sessão do Spark. Primeiramente, a biblioteca **`findspark`** é importada para permitir o uso do Spark em um ambiente Python sem a necessidade de configurar manualmente as variáveis de ambiente. Em seguida, é importada a biblioteca **`pyspark`.sql** para acessar as funcionalidades relacionadas ao SQL no Spark. A função **`init()`** do **findspark** é chamada para inicializar o Spark, e então é criada uma instância da classe **`SparkSession`** utilizando a função **`builder`**. O nome da aplicação é definido como \"onehot\" através da função **`appName`()**, e a sessão do Spark é obtida ou criada através da função **`getOrCreate`()**. Essa sessão do Spark pode então ser utilizada para realizar operações de processamento de dados distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "820ab0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"onehot\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb33b798",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo importada a biblioteca **pyspark.ml.feature** e a função **`OneHotEncoder`** dela. Essa função é utilizada para transformar variáveis categóricas em vetores de características binárias, um processo comum em análise de dados e machine learning. O **OneHotEncoder** cria uma coluna para cada categoria única na variável categórica, atribuindo o valor 1 à categoria presente e 0 às demais, permitindo que algoritmos de aprendizado de máquina entendam e processem esses dados categóricos de forma eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b654ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eea4ad",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo carregado um conjunto de dados chamado \"Churn.csv\" utilizando a **biblioteca** **`Spark`** em **`Python`**. O método ``load`` é utilizado para carregar o arquivo CSV, especificando o formato como CSV, o separador como ponto e vírgula, e inferindo o esquema dos dados. A função ``show`` é então chamada para exibir as primeiras cinco linhas do conjunto de dados carregado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28f3da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = spark.read.load(\"../Churn.csv\", format=\"csv\", sep=\";\", inferSchema=True, header=True)\n",
    "churn.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e5343",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`pyspark`**, uma biblioteca para processamento de big data em Python, especificamente o módulo de aprendizado de máquina. Primeiro, é importado o **`StringIndexer`** da biblioteca **pyspark.ml.feature**. Em seguida, duas variáveis são criadas: **indice** e **indiceonehot**. O **StringIndexer** é aplicado para transformar duas colunas do conjunto de dados, **Geography** e **Gender**, em índices numéricos, com as saídas armazenadas nas colunas **Indexer_c1** e **Indexer_c2** respectivamente. Isso é útil para algoritmos de aprendizado de máquina que exigem entradas numéricas. O método **`fit`** é usado para ajustar o **StringIndexer** ao conjunto de dados, e **`transform`** é usado para aplicar a transformação. O resultado é uma nova estrutura de dados com as colunas originais substituídas pelos índices numéricos correspondentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f8a0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indice = StringIndexer(inputCol=\"Geography\", outputCol=\"Indexer_c1\")\n",
    "indiceonehot = indice.fit(churn).transform(churn)\n",
    "\n",
    "indice = StringIndexer(inputCol=\"Gender\", outputCol=\"Indexer_c2\")\n",
    "indiceonehot = indice.fit(indiceonehot).transform(indiceonehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aa2aa2",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o método **`select`** do objeto **indiceonehot** para selecionar as colunas **Indexer_c1** duas vezes e então exibir o resultado usando o método **`show`()**. Este código provavelmente faz parte de um processo de transformação de dados em um contexto de aprendizado de máquina, onde o objetivo pode ser visualizar o resultado da codificação one-hot de uma ou mais colunas do conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7dcb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Indexer_c1|Indexer_c1|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       2.0|       2.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       2.0|       2.0|\n",
      "|       2.0|       2.0|\n",
      "|       0.0|       0.0|\n",
      "|       1.0|       1.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       2.0|       2.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       2.0|       2.0|\n",
      "|       1.0|       1.0|\n",
      "|       1.0|       1.0|\n",
      "|       2.0|       2.0|\n",
      "|       2.0|       2.0|\n",
      "|       0.0|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indiceonehot.select(\"Indexer_c1\",\"Indexer_c1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8f1cf",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`OneHotEncoder`** para transformar variáveis categóricas em vetores binários. Primeiro, é criado um objeto **onehot** que especifica as colunas de entrada e saída para a codificação one-hot. Em seguida, é criado um modelo utilizando a função **`fit`** com os dados de entrada **indiceonehot**. Após o ajuste do modelo, é aplicada a transformação utilizando a função **`transform`**, e os resultados são armazenados na variável **onehotout**. Por fim, é selecionado um subconjunto das colunas codificadas utilizando o método **`select`** e exibido na tela utilizando o método **`show`**. Este código é útil para converter variáveis categóricas em um formato adequado para serem utilizadas em algoritmos de aprendizado de máquina que requerem entradas numéricas, como regressão logística ou redes neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417e8a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|onehot_c1    |onehot_c2    |\n",
      "+-------------+-------------+\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[1],[1.0])|(2,[1],[1.0])|\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[1],[1.0])|(2,[1],[1.0])|\n",
      "|(2,[1],[1.0])|(2,[1],[1.0])|\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[],[])    |(2,[],[])    |\n",
      "|(2,[0],[1.0])|(2,[0],[1.0])|\n",
      "+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onehot = OneHotEncoder(inputCols=[\"Indexer_c1\",\"Indexer_c1\"], outputCols=[\"onehot_c1\",\"onehot_c2\"])\n",
    "modelo = onehot.fit(indiceonehot)\n",
    "onehotout = modelo.transform(indiceonehot)\n",
    "\n",
    "onehotout.select(\"onehot_c1\",\"onehot_c2\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
