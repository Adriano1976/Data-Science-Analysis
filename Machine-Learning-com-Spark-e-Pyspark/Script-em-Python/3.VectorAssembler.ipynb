{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa355a01-e48d-4041-9461-70945aefc8b5",
   "metadata": {},
   "source": [
    "### Prof. Fernando Amaral - www.eia.ai\n",
    "### Contribuição: Adriano Santos\n",
    "#### <strong><font color=orange>Machine Learning com Spark</font></strong>\n",
    "## <strong>`VectorAssembler`</strong>\n",
    "\n",
    "VectorAssembler é uma ferramenta usada no processamento de dados e aprendizado de máquina. Ela é responsável por transformar e combinar múltiplas colunas de dados em uma única coluna de vetores de características, que pode ser usada para alimentar modelos de aprendizado de máquina. Essencialmente, o `VectorAssembler` coleta e organiza dados de diferentes fontes para criar um conjunto de dados otimizado para análise preditiva ou algoritmos de classificação.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0549bc",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`findspark`** para localizar a instalação do Spark no sistema e o **`pyspark`** para importar a biblioteca do Spark para Python. Em seguida, é importada a classe **`SparkSession`** do módulo **pyspark.sql** para criar uma sessão Spark. O **findspark.init()** é chamado para configurar a variável de ambiente do Spark. A sessão Spark é criada utilizando o método **`builder`** da classe **`SparkSession`**, com o nome da aplicação definido como \"../vectorassembler\". Essa aplicação pode ser identificada no cluster Spark UI. O método **`getOrCreate`()** é usado para obter a sessão Spark existente ou criar uma nova, se necessário. Ao final, a sessão Spark está pronta para ser utilizada para processamento de dados distribuído com o Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b95ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"../vectorassembler\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116c93c",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o módulo **`pyspark`.ml.feature** para importar a função **`VectorAssembler`**. Essa função é comumente usada em processamento de dados com o Apache Spark para ajudar na preparação de dados para modelos de aprendizado de máquina. O **`VectorAssembler`** é responsável por combinar uma lista de colunas em um único vetor de recurso, que é frequentemente usado como entrada em algoritmos de machine learning. Ele simplifica o processo de construção de recursos, especialmente quando se trabalha com conjuntos de dados que possuem várias colunas que precisam ser combinadas em uma única entrada para o modelo. Isso pode incluir, por exemplo, a combinação de recursos numéricos e categóricos em um único vetor para que o modelo possa ser treinado de maneira eficaz. Em resumo, o **`VectorAssembler`** é uma ferramenta essencial para transformar dados em um formato adequado para o treinamento de modelos de machine learning no ambiente do Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6012b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee23494",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo feita a leitura de um arquivo CSV de carros utilizando a biblioteca **spark** em Python. A função **spark.read.csv** é utilizada para ler o arquivo \"Carros.csv\" e criar um DataFrame no ambiente do Spark. Os parâmetros **header=True** e **inferSchema=True** indicam que a primeira linha do arquivo contém os nomes das colunas e que o Spark deve inferir os tipos de dados das colunas, respectivamente. O parâmetro **sep=\";\"** especifica que o separador no arquivo CSV é o ponto e vírgula. Em seguida, a função **carros.show(5)** é chamada para exibir as primeiras cinco linhas do DataFrame, proporcionando uma visão inicial dos dados carregados. Essas linhas de código são fundamentais para a etapa de leitura e visualização dos dados do arquivo CSV, preparando-os para análises posteriores dentro do ambiente do Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0582dc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        160|             39|2875| 1702|        0|          1|      4|          4|110|\n",
      "|    228|        4|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        6|        258|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        8|        360|            315| 344| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carros = spark.read.csv(\"../Carros.csv\", header=True, inferSchema=True, sep=\";\")\n",
    "carros.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f5901",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o método **`VectorAssembler`** para criar um vetor de características a partir das colunas de entrada, que incluem variáveis como **Consumo**, **Cilindros**, **Cilindradas**, entre outras. Esse vetor resultante é atribuído à variável **caracteristicas**. Em seguida, o conjunto de dados **carros** é transformado utilizando esse vetor de características, onde cada linha do conjunto de dados é agora representada por um vetor contendo as características especificadas. Este processo é comumente utilizado em tarefas de aprendizado de máquina para preparar os dados para modelagem, reunindo várias características em um único vetor para facilitar a análise e o processamento pelos algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58c662ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectas = VectorAssembler(\n",
    "    inputCols = [\"Consumo\",\"Cilindros\",\"Cilindradas\",\"RelEixoTraseiro\",\"Peso\",\"Tempo\",\"TipoMotor\",\"Transmissao\",\"Marchas\",\"Carburadors\"],\n",
    "    outputCol = \"caracteristicas\"\n",
    ")\n",
    "\n",
    "carros = vectas.transform(carros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41200eb",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o método **select** do objeto **carros** para selecionar a coluna de características dos carros. Em seguida, o método **show** é aplicado para exibir os dados dessa coluna em formato de tabela, sem truncamento, ou seja, exibindo todas as informações. O parâmetro **truncate=False** garante que os dados não serão truncados na exibição, permitindo visualizar todas as características dos carros sem limitações de tamanho. Essa sequência de comandos é comumente utilizada em análises de dados com a biblioteca **pandas** em Python, permitindo visualizar facilmente os dados de uma coluna específica de um DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc03dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+\n",
      "|caracteristicas                                      |\n",
      "+-----------------------------------------------------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |\n",
      "|[181.0,6.0,225.0,276.0,346.0,2022.0,1.0,0.0,3.0,1.0] |\n",
      "|[143.0,8.0,360.0,321.0,357.0,1584.0,0.0,0.0,3.0,4.0] |\n",
      "|[244.0,4.0,1467.0,369.0,319.0,20.0,1.0,0.0,4.0,2.0]  |\n",
      "|[228.0,4.0,1408.0,392.0,315.0,229.0,1.0,0.0,4.0,2.0] |\n",
      "|[192.0,6.0,1676.0,392.0,344.0,183.0,1.0,0.0,4.0,4.0] |\n",
      "|[178.0,6.0,1676.0,392.0,344.0,189.0,1.0,0.0,4.0,4.0] |\n",
      "|[164.0,8.0,2758.0,307.0,407.0,174.0,0.0,0.0,3.0,3.0] |\n",
      "|[173.0,8.0,2758.0,307.0,373.0,176.0,0.0,0.0,3.0,3.0] |\n",
      "|[152.0,8.0,2758.0,307.0,378.0,18.0,0.0,0.0,3.0,3.0]  |\n",
      "|[104.0,8.0,472.0,293.0,525.0,1798.0,0.0,0.0,3.0,4.0] |\n",
      "|[104.0,8.0,460.0,3.0,5424.0,1782.0,0.0,0.0,3.0,4.0]  |\n",
      "|[147.0,8.0,440.0,323.0,5345.0,1742.0,0.0,0.0,3.0,4.0]|\n",
      "|[324.0,4.0,787.0,408.0,22.0,1947.0,1.0,1.0,4.0,1.0]  |\n",
      "|[304.0,4.0,757.0,493.0,1615.0,1852.0,1.0,1.0,4.0,2.0]|\n",
      "|[339.0,4.0,711.0,422.0,1835.0,199.0,1.0,1.0,4.0,1.0] |\n",
      "+-----------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carros.select(\"caracteristicas\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef68b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
