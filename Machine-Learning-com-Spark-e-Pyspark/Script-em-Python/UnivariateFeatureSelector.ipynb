{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c883dc-d21d-4676-b937-55d687f60225",
   "metadata": {},
   "source": [
    "### Prof. Fernando Amaral - www.eia.ai\n",
    "### Contribuição: Adriano Santos\n",
    "#### <strong><font color=orange>Machine Learning com Spark</font></strong>\n",
    "## <strong>`UnivariateFeatureSelector`</strong>\n",
    "`UnivariateFeatureSelector` é uma abstração genérica no Apache Spark MLlib para seletores de características univariados, que operam sobre um conjunto de características individuais de um dataset. Esses seletores são usados para ***identificar e manter apenas as características mais relevantes para a tarefa de modelagem***, baseando-se em critérios univariados, como a importância de uma única característica para a divisão entre classes. A ideia por trás do uso de `UnivariateFeatureSelector` é ***simplificar o modelo mantendo apenas as características que têm um impacto significativo na predição***, ajudando a evitar overfitting e melhorando a generalização do modelo.\n",
    "</br>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b6e1f",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizada a **biblioteca** `findspark` para inicializar o ambiente do Spark e a **biblioteca** `pyspark.sql` para criar uma **sessão Spark**. Inicialmente, a **função** `findspark.init()` é chamada para configurar o ambiente do Spark. Em seguida, uma instância da **classe** `SparkSession` é criada com o nome da aplicação definido como \"univariatefeatureselector\", utilizando o **método** `builder.appName()`. A criação da sessão Spark é concluída com a chamada ao **método** `getOrCreate()`, que inicia ou recupera uma sessão Spark existente. Este setup é essencial para utilizar as funcionalidades de análise de dados e aprendizado de máquina fornecidas pelo Spark, incluindo ferramentas como `UnivariateFeatureSelector` e `RFormula` da **biblioteca** `pyspark.ml.feature`, que são mencionadas mas não utilizadas diretamente no trecho apresentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a202f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import UnivariateFeatureSelector, RFormula\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"univariatefeatureselector\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560e4ee",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo usada a **biblioteca** Spark para ler um arquivo CSV contendo dados de carros. A **função** `spark.read.csv` é utilizada para carregar o arquivo \"../Carros.csv\" com as seguintes **parâmetros**: `header=True`, indicando que o arquivo possui cabeçalhos, `inferSchema=True`, que permite a inferência automática dos tipos de dados das colunas, e `sep=\";\"`, definindo o separador de campos como ponto e vírgula. Em seguida, a **função** `show(5)` é chamada para exibir as primeiras cinco linhas do DataFrame resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "910e73b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|Consumo|Cilindros|Cilindradas|RelEixoTraseiro|Peso|Tempo|TipoMotor|Transmissao|Marchas|Carburadors| HP|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "|     21|        6|        160|             39| 262| 1646|        0|          1|      4|          4|110|\n",
      "|     21|        6|        160|             39|2875| 1702|        0|          1|      4|          4|110|\n",
      "|    228|        4|        108|            385| 232| 1861|        1|          1|      4|          1| 93|\n",
      "|    214|        6|        258|            308|3215| 1944|        1|          0|      3|          1|110|\n",
      "|    187|        8|        360|            315| 344| 1702|        0|          0|      3|          2|175|\n",
      "+-------+---------+-----------+---------------+----+-----+---------+-----------+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carros = spark.read.csv(\"../Carros.csv\", header=True, inferSchema=True, sep=\";\")\n",
    "carros.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f2f9b",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizada a **biblioteca** `RFormula` do **Spark** para transformar um conjunto de dados de carros. A **classe** `RFormula` é inicializada com a **fórmula** `\"HP ~ .\"` indicando que a variável dependente é `HP` e todas as outras colunas são independentes. A **instância** `RFormula` é configurada com os parâmetros `featuresCol` como \"independente\" e `labelCol` como \"dependente\". O **método** `fit` é aplicado ao DataFrame `carros` para ajustar o modelo, seguido pelo **método** `transform` para transformar os dados. Finalmente, as colunas \"independente\" e \"dependente\" do DataFrame transformado `carrosrf` são selecionadas e exibidas usando a **função** `select` e `show`, respectivamente, sem truncamento dos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af87a66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------+----------+\n",
      "|independente                                         |dependente|\n",
      "+-----------------------------------------------------+----------+\n",
      "|[21.0,6.0,160.0,39.0,262.0,1646.0,0.0,1.0,4.0,4.0]   |110.0     |\n",
      "|[21.0,6.0,160.0,39.0,2875.0,1702.0,0.0,1.0,4.0,4.0]  |110.0     |\n",
      "|[228.0,4.0,108.0,385.0,232.0,1861.0,1.0,1.0,4.0,1.0] |93.0      |\n",
      "|[214.0,6.0,258.0,308.0,3215.0,1944.0,1.0,0.0,3.0,1.0]|110.0     |\n",
      "|[187.0,8.0,360.0,315.0,344.0,1702.0,0.0,0.0,3.0,2.0] |175.0     |\n",
      "|[181.0,6.0,225.0,276.0,346.0,2022.0,1.0,0.0,3.0,1.0] |105.0     |\n",
      "|[143.0,8.0,360.0,321.0,357.0,1584.0,0.0,0.0,3.0,4.0] |245.0     |\n",
      "|[244.0,4.0,1467.0,369.0,319.0,20.0,1.0,0.0,4.0,2.0]  |62.0      |\n",
      "|[228.0,4.0,1408.0,392.0,315.0,229.0,1.0,0.0,4.0,2.0] |95.0      |\n",
      "|[192.0,6.0,1676.0,392.0,344.0,183.0,1.0,0.0,4.0,4.0] |123.0     |\n",
      "|[178.0,6.0,1676.0,392.0,344.0,189.0,1.0,0.0,4.0,4.0] |123.0     |\n",
      "|[164.0,8.0,2758.0,307.0,407.0,174.0,0.0,0.0,3.0,3.0] |180.0     |\n",
      "|[173.0,8.0,2758.0,307.0,373.0,176.0,0.0,0.0,3.0,3.0] |180.0     |\n",
      "|[152.0,8.0,2758.0,307.0,378.0,18.0,0.0,0.0,3.0,3.0]  |180.0     |\n",
      "|[104.0,8.0,472.0,293.0,525.0,1798.0,0.0,0.0,3.0,4.0] |205.0     |\n",
      "|[104.0,8.0,460.0,3.0,5424.0,1782.0,0.0,0.0,3.0,4.0]  |215.0     |\n",
      "|[147.0,8.0,440.0,323.0,5345.0,1742.0,0.0,0.0,3.0,4.0]|230.0     |\n",
      "|[324.0,4.0,787.0,408.0,22.0,1947.0,1.0,1.0,4.0,1.0]  |66.0      |\n",
      "|[304.0,4.0,757.0,493.0,1615.0,1852.0,1.0,1.0,4.0,2.0]|52.0      |\n",
      "|[339.0,4.0,711.0,422.0,1835.0,199.0,1.0,1.0,4.0,1.0] |65.0      |\n",
      "+-----------------------------------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Rformula = RFormula(formula=\"HP ~ .\", featuresCol=\"independente\", labelCol=\"dependente\")\n",
    "carrosrf = Rformula.fit(carros).transform(carros)\n",
    "\n",
    "carrosrf.select(\"independente\", \"dependente\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14979ebf",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo realizada a seleção de características univariadas de um conjunto de dados. A **classe** `UnivariateFeatureSelector` é utilizada para criar um objeto `selector` com as colunas de entrada e saída especificadas pelos **parâmetros** `featuresCol`, `outputCol` e `labelCol`. As **funções** `setFeatureType` e `setLabelType` são chamadas para definir os tipos de dados das características e do rótulo como contínuos. Além disso, a **função** `setSelectionThreshold` define o limiar de seleção para 5 características. Em seguida, o método `fit` é utilizado para ajustar o seletor aos dados do **DataFrame** `carrosrf`, e o método `transform` aplica a transformação, resultando no **DataFrame** `carrosuni` com as características selecionadas. Por fim, a **função** `select` é usada para selecionar e exibir as primeiras 5 linhas da coluna `selecionados` sem truncamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651418fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|selecionados           |\n",
      "+-----------------------+\n",
      "|[21.0,6.0,0.0,1.0,4.0] |\n",
      "|[21.0,6.0,0.0,1.0,4.0] |\n",
      "|[228.0,4.0,1.0,1.0,1.0]|\n",
      "|[214.0,6.0,1.0,0.0,1.0]|\n",
      "|[187.0,8.0,0.0,0.0,2.0]|\n",
      "+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selector = UnivariateFeatureSelector(featuresCol=\"independente\", outputCol=\"selecionados\", labelCol=\"dependente\")\n",
    "selector.setFeatureType(\"continuous\").setLabelType(\"continuous\").setSelectionThreshold(5)\n",
    "carrosuni = selector.fit(carrosrf).transform(carrosrf)\n",
    "carrosuni.select(\"selecionados\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b896eff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
