{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6567aa-0e6e-461b-9ddf-80f95ad63b65",
   "metadata": {},
   "source": [
    "### Prof. Fernando Amaral - www.eia.ai\n",
    "### Contribuição: Adriano Santos\n",
    "#### <strong><font color=orange>Machine Learning com Spark</font></strong>\n",
    "## <strong>`IndexToString`</strong>\n",
    "\n",
    "A função do IndexToString é converter um índice de volta para a categoria original. \"Converter de volta um índice para a categoria\" significa transformar um valor numérico, típico de um índice ou código, em uma representação mais compreensível ou significativa, geralmente relacionada a uma categoria específica. Por exemplo, se tivermos um índice numérico que representa os tipos de produtos (1 para eletrônicos, 2 para roupas, etc.), converter de volta para a categoria significa atribuir a cada número o nome da categoria correspondente. Portanto, o `IndexToString` pode ser usado para mostrar valores \"reais\" ao converter os índices de volta para suas categorias correspondentes. Ele cria um atributo com a coluna original, permitindo que os valores \"reais\" sejam exibidos quando necessário.\n",
    "<br><br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f2823",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`findspark`** para localizar o Spark na máquina, junto com a biblioteca **`pyspark`**. Em seguida, é importada a classe **`SparkSession`** do módulo **pyspark.sql**. O método **`init`()** é chamado para inicializar o **`findspark`**, permitindo que o Spark seja localizado. Uma sessão Spark é então criada utilizando o método **`builder`**, onde o nome da aplicação é definido como \"indextostring\". Essa sessão é armazenada na variável **spark**. Este código tem como objetivo iniciar uma sessão Spark para processamento de dados utilizando a biblioteca **`pyspark`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355b54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "findspark.init()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"indextostring\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd767b74",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`pyspark`**, uma biblioteca para processamento de big data em Python. A linha de código importa a classe **`StringIndexer`** do módulo **`feature`** dessa biblioteca. O **`StringIndexer`** é uma função que converte rótulos de strings em índices de números inteiros, o que é útil para o pré-processamento de dados categóricos em algoritmos de aprendizado de máquina. Ele atribui um índice único a cada valor distinto na coluna de strings, facilitando o processamento e a análise subsequentes dos dados. Essa funcionalidade é comumente utilizada em pipelines de Machine Learning no ambiente do Spark para lidar com dados categóricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b0de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89552d26",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo carregado um conjunto de dados chamado \"Churn.csv\" usando a biblioteca **`spark`** do Apache Spark em Python. O conjunto de dados é lido a partir do arquivo \"../Churn.csv\", utilizando o formato CSV e configurando o separador como ponto e vírgula. A opção \"`inferSchema`\" é definida como verdadeira para inferir automaticamente os tipos de dados das colunas, enquanto \"`header`\" é configurado como verdadeiro para indicar que a primeira linha contém os nomes das colunas. Em seguida, os primeiros cinco registros do conjunto de dados são mostrados na saída usando a função **`show`(5)**. Este código é útil para carregar e visualizar rapidamente os primeiros registros de um conjunto de dados no ambiente do Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de52277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = spark.read.load(\"../Churn.csv\", format=\"csv\", sep=\";\", inferSchema=True, header=True)\n",
    "\n",
    "churn.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedf40f6",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`StringIndexer`** para transformar a coluna \"Geography\" em índices numéricos, armazenados na coluna \"indice\". Primeiro, é criado um objeto **StringIndexer** especificando a coluna de entrada como \"Geography\" e a coluna de saída como \"indice\". Em seguida, o modelo é ajustado aos dados de churn utilizando o método **`fit`**. Posteriormente, os dados são transformados com o método **`transform`** o modelo ajustado, e apenas as colunas \"Geography\" e \"indice\" são selecionadas com o método **`select`** e exibidas para as primeiras 10 linhas usando o método **`show`**. Este código é útil para codificar variáveis categóricas em um formato numérico para posterior uso em modelos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe203eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|Geography|indice|\n",
      "+---------+------+\n",
      "|   France|   0.0|\n",
      "|    Spain|   2.0|\n",
      "|   France|   0.0|\n",
      "|   France|   0.0|\n",
      "|    Spain|   2.0|\n",
      "|    Spain|   2.0|\n",
      "|   France|   0.0|\n",
      "|  Germany|   1.0|\n",
      "|   France|   0.0|\n",
      "|   France|   0.0|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indice = StringIndexer(inputCol=\"Geography\", outputCol=\"indice\")\n",
    "modelo = indice.fit(churn)\n",
    "dadoscomindice = modelo.transform(churn)\n",
    "\n",
    "dadoscomindice.select(\"Geography\",\"indice\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64194aed",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`pyspark`**, uma biblioteca para processamento distribuído em Python. Importa-se a função **`IndexToString`** da biblioteca **pyspark.ml.feature** para realizar uma conversão de índices para valores originais. A variável **retorno** é criada para configurar a conversão, especificando a coluna de entrada como **\"indice\"** e a coluna de saída como **\"categoriaoriginal\"**. Em seguida, aplica-se essa transformação aos dados contidos na variável **dadoscomindice** e armazena-se o resultado na variável **convertido**. Por fim, seleciona-se algumas colunas (**\"Geography\"**, **\"indice\"** e **\"categoriaoriginal\"**) do DataFrame convertido e exibe-se as primeiras cinco linhas utilizando o método **`show`(5)**. Este código é útil em análises de dados com o Spark, principalmente para converter índices numéricos de categorias em seus valores originais, facilitando a interpretação dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dfa6414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----------------+\n",
      "|Geography|indice|categoriaoriginal|\n",
      "+---------+------+-----------------+\n",
      "|   France|   0.0|           France|\n",
      "|    Spain|   2.0|            Spain|\n",
      "|   France|   0.0|           France|\n",
      "|   France|   0.0|           France|\n",
      "|    Spain|   2.0|            Spain|\n",
      "+---------+------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "\n",
    "retorno = IndexToString(inputCol=\"indice\", outputCol=\"categoriaoriginal\")\n",
    "convertido = retorno.transform(dadoscomindice)\n",
    "\n",
    "convertido.select(\"Geography\",\"indice\",\"categoriaoriginal\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea1ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
