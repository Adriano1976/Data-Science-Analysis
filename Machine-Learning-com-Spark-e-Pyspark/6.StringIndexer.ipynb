{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65dae4e3-1158-4cfe-bf3d-941cc6bb6224",
   "metadata": {},
   "source": [
    "### Prof. Fernando Amaral - www.eia.ai\n",
    "### Contribuição: Adriano Santos\n",
    "#### <strong><font color=orange>Machine Learning com Spark</font></strong>\n",
    "## <strong>`StringIndexer`</strong>\n",
    "\n",
    "O modelo criado com um conjunto de dados no StringIndexer é usado para transformar outros conjuntos de dados. Ele atribui números únicos para cada categoria encontrada nos dados de treinamento. Os itens mais frequentes recebem números menores. Para lidar com rótulos não conhecidos, você pode usar o parâmetro \"`handleInvalid`\" com os valores \"`error`\" (exceção padrão), \"`skip`\" (omitir) ou \"`keep`\" (colocar em uma categoria especial chamada \"desconhecidos\"). \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e295fe9",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o **`findspark`** para localizar e configurar o ambiente do Spark no Python. Em seguida, são importados os módulos necessários do **`pyspark`**, incluindo o **`SparkSession`** da biblioteca **pyspark.sql**. A função **`init`()** é chamada para inicializar o Spark, e em seguida, é criada uma sessão Spark utilizando o **SparkSession.builder**, com o nome de aplicação definido como \"stringindexer\". Essa sessão Spark é atribuída à variável **spark**. Esse código é utilizado para configurar e iniciar o ambiente Spark no Python, preparando-o para realizar operações de processamento de dados distribuídos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e844abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark, pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "findspark.init()\n",
    "spark = SparkSession.builder.appName(\"stringindexer\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f9e92c",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo utilizado o módulo **pyspark.ml.feature** para importar a função **`StringIndexer`**. Esta função é usada para converter uma coluna de strings em uma coluna de índices numéricos em um DataFrame Spark. Por exemplo, se houver uma coluna de categorias como \"A\", \"B\" e \"C\", o StringIndexer atribuirá o índice 0 para \"A\", 1 para \"B\" e 2 para \"C\". Isso é útil para preparar dados de texto para algoritmos de aprendizado de máquina, que geralmente requerem entradas numéricas. Com a conversão para índices numéricos, as strings podem ser usadas como características em modelos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26a2db9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ad899",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo realizado o carregamento de um conjunto de dados chamado \"Churn.csv\" para análise de churn utilizando o Spark. A variável **churn** recebe os dados do arquivo CSV com o auxílio da função **spark.read.load**. A função **`load`** é usada para carregar o arquivo, especificando o caminho do arquivo, o formato do arquivo (no caso, CSV), o separador de campos (ponto e vírgula), a inferência do esquema (inferSchema=True) para determinar automaticamente os tipos de dados das colunas e o cabeçalho (header=True) para indicar que a primeira linha contém os nomes das colunas. Em seguida, a função **`show`** é usada para exibir as primeiras cinco linhas do conjunto de dados, facilitando a visualização inicial da estrutura e dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb059b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|CreditScore|Geography|Gender|Age|Tenure| Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "|        619|   France|Female| 42|     2|       0|            1|        1|             1|       10134888|     1|\n",
      "|        608|    Spain|Female| 41|     1| 8380786|            1|        0|             1|       11254258|     0|\n",
      "|        502|   France|Female| 42|     8| 1596608|            3|        1|             0|       11393157|     1|\n",
      "|        699|   France|Female| 39|     1|       0|            2|        0|             0|        9382663|     0|\n",
      "|        850|    Spain|Female| 43|     2|12551082|            1|        1|             1|         790841|     0|\n",
      "+-----------+---------+------+---+------+--------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "churn = spark.read.load(\"../Churn.csv\", format=\"csv\", sep=\";\", inferSchema=True, header=True)\n",
    "churn.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624e62f",
   "metadata": {},
   "source": [
    "No código a seguir, está sendo realizado o processo de indexação de uma coluna chamada \"Geography\" usando a biblioteca **`StringIndexer`** do **Apache Spark** em Python. Primeiramente, é criado um objeto **indice** que recebe a função **`StringIndexer`**, onde é especificado que a coluna de entrada é \"Geography\" e a coluna de saída é denominada como \"indice\". Em seguida, é instanciado um modelo utilizando o método **`fit`** aplicado ao objeto **indice**, que é treinado com os dados fornecidos pelo dataframe **churn**. Posteriormente, a indexação é aplicada aos dados do dataframe **churn** e o resultado é armazenado no dataframe **dadoscomindice**. Por fim, são selecionadas as colunas \"Geography\" e \"indice\" do dataframe resultante e são exibidas as primeiras 10 linhas utilizando o método **`show`**. Essa indexação é útil para transformar dados categóricos em numéricos, facilitando o processamento por algoritmos de machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c671340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|Geography|indice|\n",
      "+---------+------+\n",
      "|   France|   0.0|\n",
      "|    Spain|   2.0|\n",
      "|   France|   0.0|\n",
      "|   France|   0.0|\n",
      "|    Spain|   2.0|\n",
      "|    Spain|   2.0|\n",
      "|   France|   0.0|\n",
      "|  Germany|   1.0|\n",
      "|   France|   0.0|\n",
      "|   France|   0.0|\n",
      "+---------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indice = StringIndexer(inputCol=\"Geography\", outputCol=\"indice\")\n",
    "modelo = indice.fit(churn)\n",
    "dadoscomindice = modelo.transform(churn)\n",
    "\n",
    "dadoscomindice.select(\"Geography\",\"indice\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a28fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
