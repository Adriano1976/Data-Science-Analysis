{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='gree'>Fundamentos de Linguagem Python Para Análise de Dados e Data Science</font>\n",
    "\n",
    "## <font color='gree'>Construindo Chatbot Personalizado com GPT e Linguagem Python</font>\n",
    "\n",
    "Problema de Negócio:\n",
    "\n",
    "#### Vamos construir um chatbot personalizado usando o modelo de linguagem GPT-3.5 e Linguagem Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Verificar a Versão da Linguagem Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse código Python exibe a versão da linguagem Python que está sendo usada no ambiente do Jupyter Notebook. Ele importa a função `python_version` do módulo `platform` e, em seguida, imprime a versão do Python. Isso é útil para verificar a versão da linguagem e garantir que seu código seja compatível com essa versão específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.11.3\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Instalar os pacotes necessário</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código em Python utiliza o módulo `pkg_resources` para verificar a instalação de pacotes necessários, como \"`openai`\", \"`requests`\" e \"`nest_asyncio`\". Ele percorre a lista de pacotes requeridos, tentando obter a distribuição de cada um. Se um pacote não for encontrado, o código indica que não está instalado e procede com a instalação usando o comando `%pip install {package}`. Essa abordagem ajuda a garantir que todas as dependências estejam presentes, facilitando a execução do script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai (0.28.0) está instalado\n",
      "requests (2.29.0) está instalado\n",
      "nest-asyncio (1.5.6) está instalado\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "REQUIRED_PACKAGES = [\"openai\", \"requests\", \"nest_asyncio\"]\n",
    "\n",
    "for package in REQUIRED_PACKAGES:\n",
    "    try:\n",
    "        dist = pkg_resources.get_distribution(package)\n",
    "        print(f\"{dist.key} ({dist.version}) está instalado\")\n",
    "    except pkg_resources.DistributionNotFound:\n",
    "        print(f\"{package} NÃO está instalado. Instalando agora...\")\n",
    "        %pip install {package}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Importar e Realizar a definição da chave de APT</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código Python apresentado é utilizado para construir um chatbot personalizado com a versão 3.5 do modelo GPT da OpenAI, utilizando a linguagem Python. Inicialmente, é feito o import da biblioteca \"`openai`\" e, em seguida, a chave de API é configurada. Essa chave é essencial para autenticar o acesso aos serviços da OpenAI. O código serve como base para interações com o GPT-3.5, permitindo a criação de um chatbot customizado para diversas aplicações, desde que a chave de API seja válida e a biblioteca \"`openai`\" esteja instalada no ambiente de desenvolvimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Criar uma função para gerar texto a partir do modelo de linguagem</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código em Python utiliza o módulo `nest_asyncio` para permitir execução assíncrona, essencial para operações como chamadas à API. A função `gera_texto` usa o modelo de linguagem GPT-3.5-turbo da OpenAI para gerar texto com base no prompt fornecido. A configuração inclui parâmetros como o comprimento máximo dos tokens (150), o número de conclusões geradas para cada prompt (5), e a temperatura que influencia a aleatoriedade do texto gerado (0.8). O código é bem estruturado, integrando as capacidades do modelo de linguagem da OpenAI de maneira eficaz. A documentação oficial da OpenAI é referenciada para consulta adicional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação necessária\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# Aplicação do Nest Asyncio para permitir a execução assíncrona\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Função para gerar texto a partir do modelo de linguagem\n",
    "async def gera_texto(texto):\n",
    "    \n",
    "    # Obtém a resposta do modelo de linguagem\n",
    "    response = await openai.Completion.acreate(\n",
    "        \n",
    "        # Modelo usado\n",
    "        # Outros modelos estão disponíveis em https://platform.openai.com/account/rate-limits\n",
    "        engine = \"gpt-3.5-turbo\",\n",
    "        \n",
    "        # Texto inicial da conversa com o chatbot.\n",
    "        prompt = texto,\n",
    "        \n",
    "        # Comprimento da resposta gerada pelo modelo.\n",
    "        max_tokens = 150,\n",
    "        \n",
    "        # Quantas conclusões gerar para cada prompt.\n",
    "        n = 5,\n",
    "        \n",
    "        # O texto retornado não conterá a sequência de parada.\n",
    "        stop = None,\n",
    "        \n",
    "        # Uma medida da aleatoriedade de um texto gerado pelo modelo. Seu valor está entre 0 e 1.\n",
    "        # Valores próximos a 1 significam que a saída é mais aleatória, enquanto valores próximos a 0 significam que a saída é muito identificável.\n",
    "        temperature = 0.8,        \n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Documentação Oficial: https://platform.openai.com/docs/api-reference/introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Criar a função principal do programa em Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse código Python define a função principal de um chatbot baseado no modelo GPT-3.5. O programa inicia dando as boas-vindas ao usuário e aguarda a entrada de perguntas. Se o usuário digitar \"sair\", o loop é encerrado, finalizando o programa. Para cada pergunta do usuário, a mensagem é formatada como entrada para o modelo GPT-3.5. A função `gera_texto()` é então chamada para obter a resposta do chatbot, que é impressa na tela. O chatbot continua interagindo até que o usuário decida sair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal do programa em Python\n",
    "async def main():\n",
    "    \n",
    "    print(\"\\nBem-vindo ao GPT-3.5 Chatbot do Projeto de Curso de Ciência de Dados!\")\n",
    "    print(\"(Digite 'sair' a qualquer momento para encerrar o chat)\")\n",
    "    \n",
    "    # Loop do programa\n",
    "    while True:\n",
    "        \n",
    "        # Coleta a pergunta digitada pelo usuário.\n",
    "        user_message = input(\"\\nVocê: \")\n",
    "        \n",
    "        # Se a mensagem for \"sair\", finaliza o programa.\n",
    "        if user_message.lower() == \"sair\":\n",
    "            break\n",
    "        \n",
    "        # Coloca a mensagem digitada pelo usuário na variável Python chamada gpt_prompt.\n",
    "        gpt_prompt = f\"Usuário: {user_message} Chatbot: \"\n",
    "        \n",
    "        # Obtém a resposta do modelo executando a função 'gera_texto().'\n",
    "        chatbot_response = await gera_texto(gpt_prompt)\n",
    "        \n",
    "        # Imprime a resposta do Chatbot.\n",
    "        print(f\"\\nChatbot: {chatbot_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>Efetuar a ececutação do programa (bloco main) em Python</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No trecho de código fornecido, temos a execução principal (bloco main) em Python. A estrutura condicional verifica se o módulo está sendo executado diretamente. Dentro do bloco principal, a função `asyncio.get_event_loop().run_until_complete(main())` é chamada para executar assincronamente a função `main()`. Em caso de exceção, é capturado e exibido um aviso de erro, indicando a natureza do problema. Essa abordagem é útil para lidar com operações assíncronas de maneira controlada e capturar erros durante a execução do programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bem-vindo ao GPT-3.5 Chatbot do Projeto de Curso de Ciência de Dados!\n",
      "(Digite 'sair' a qualquer momento para encerrar o chat)\n",
      "\n",
      "Ocorreu um erro: You exceeded your current quota, please check your plan and billing details.\n"
     ]
    }
   ],
   "source": [
    "# Ececutação do programa (bloco main) em Python\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        asyncio.get_event_loop().run_until_complete(main())\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
