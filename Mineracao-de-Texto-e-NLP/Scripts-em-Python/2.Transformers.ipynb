{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formação Cientista de Dados - Prof. Fernando Amaral\n",
    "# Constribuição: Adriano Santos\n",
    "\n",
    "# Modelo Huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intalando a biblioteca \"transformers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse código começa com a linha \"!pip install transformers\", que é um comando utilizado para instalar uma biblioteca chamada \"transformers\" no ambiente Python caso não tenha instalado. Essa biblioteca é amplamente usada no processamento de linguagem natural e fornece modelos pré-treinados para tarefas como tradução de idiomas, resumo de texto e análise de sentimentos. Portanto, ao executar esse código, os futuros profissionais estarão instalando uma ferramenta importante para trabalhar com tarefas avançadas de processamento de texto em Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDDlAm3ztp3T"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse código Python utiliza a biblioteca \"transformers\" para tarefas relacionadas ao processamento de linguagem natural (NLP). Primeiro, ele importa as bibliotecas necessárias, incluindo \"transformers\" e \"pipeline\". A biblioteca \"transformers\" é amplamente utilizada para treinar e utilizar modelos de aprendizado profundo em NLP, enquanto \"pipeline\" simplifica a aplicação desses modelos em tarefas específicas, como tradução ou análise de sentimentos. Esse código serve como ponto de partida para profissionais que desejam explorar a potencialidade do NLP usando modelos pré-treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "i_kgTxNOt-Ow"
   },
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização do pipeline para question-answering com o modelo adequado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse código em Python realiza a inicialização de um pipeline para realizar question-answering, ou seja, responder a perguntas automaticamente. Ele utiliza o modelo \"pierreguillou/bert-base-cased-squad-v1.1-portuguese\", que é treinado em língua portuguesa e projetado para responder a perguntas com base no contexto fornecido. Essa ferramenta pode ser valiosa para futuros profissionais que desejam desenvolver aplicações de processamento de linguagem natural em português, facilitando a obtenção de respostas para perguntas específicas a partir de textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ACzD8vVjuKrq"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e5e4445b0645dfb671aeec322cd487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/862 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilma Ferreira\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nilma Ferreira\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0479e7240441a8b29b33d14111b3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/434M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at pierreguillou/bert-base-cased-squad-v1.1-portuguese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb553664b3a94bcd8534ab68f83a49e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/494 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c684890ac57f46f298875b5485518a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70cf7a0852d443a828cd2073da5eafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inicialização do pipeline para question-answering com o modelo adequado\n",
    "qea = pipeline(\"question-answering\", model=\"pierreguillou/bert-base-cased-squad-v1.1-portuguese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando biblioteca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando um modelo específico para responder questionamentos e respostas automatizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste código Python, primeiro definimos duas variáveis: \"texto\" e \"pergunta\". O \"texto\" contém informações sobre Carl Sagan e suas realizações científicas, enquanto a \"pergunta\" é formulada para saber quantas publicações científicas Carl Sagan tem. Em seguida, é feita uma consulta à biblioteca \"qea\" usando a pergunta e o contexto do texto. Por fim, os resultados, incluindo a pergunta, a resposta obtida e o score associado à resposta, são exibidos no console. Esse código provavelmente faz parte de um sistema de questionamento e resposta automatizado, onde a biblioteca \"qea\" é usada para encontrar respostas em um texto dado com base em uma pergunta específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cdEl6q7u88Y",
    "outputId": "06c8cdbb-0ba5-4c42-f102-237087345cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta:  Quantas publicações cientificas Carl Sagan tem publicado?\n",
      "Resposta:  mais de 600\n",
      "Score:  0.7415892481803894\n"
     ]
    }
   ],
   "source": [
    "# Definição das variáveis\n",
    "texto = \"Carl Sagan foi um cientista norte-americano. Sagan é autor de mais de 600 publicações científicas e também de mais de vinte livros de ciência e ficção científica.\"\n",
    "pergunta = \"Quantas publicações cientificas Carl Sagan tem publicado?\"\n",
    "\n",
    "# Consulta à biblioteca qea\n",
    "resposta = qea(question=pergunta, context=texto)\n",
    "\n",
    "# Exibição dos resultados\n",
    "print(\"Pergunta: \", pergunta)\n",
    "print(\"Resposta: \", resposta['answer'])\n",
    "print(\"Score: \", resposta['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nq4OI4Rtv5Bg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "perguntaserespostas.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
